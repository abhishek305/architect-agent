# ğŸ“ Document Architect

An AI-powered toolkit that interviews you like a Senior PM or Principal Engineer to generate professional documentation and implementation-ready artifacts.

Built with [Mastra.ai](https://mastra.ai) - a TypeScript framework for building AI agents with tools, memory, and workflows.

---

## âœ¨ Features

### Three Agents, One Workflow

| Agent | Persona | Output |
|-------|---------|--------|
| **ğŸ“‹ Architect Agent** | Senior PM / Principal Engineer | PRDs & TDRs |
| **âš›ï¸ Frontend Architect Agent** | React/Next.js Expert | Frontend TDRs |
| **ğŸ› ï¸ Story Builder Agent** | Senior Agile Coach | User Stories & Epics |

### Workflow Chain: PRD â†’ TDR â†’ Stories

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Architect Agent â”‚ â†’  â”‚ Frontend Arch   â”‚ â†’  â”‚ Architect Agent â”‚ â†’  â”‚ Story Builder   â”‚
â”‚   (PRD Mode)    â”‚    â”‚     Agent       â”‚    â”‚   (TDR Mode)    â”‚    â”‚     Agent       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ User problems â”‚    â”‚ â€¢ React patternsâ”‚    â”‚ â€¢ Backend arch  â”‚    â”‚ â€¢ Epics         â”‚
â”‚ â€¢ Success KPIs  â”‚    â”‚ â€¢ Next.js configâ”‚    â”‚ â€¢ Security      â”‚    â”‚ â€¢ User Stories  â”‚
â”‚ â€¢ Requirements  â”‚    â”‚ â€¢ Performance   â”‚    â”‚ â€¢ Scalability   â”‚    â”‚ â€¢ Test Cases    â”‚
â”‚ â€¢ Timeline      â”‚    â”‚ â€¢ Accessibility â”‚    â”‚ â€¢ Code examples â”‚    â”‚ â€¢ Sprint Plan   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“                       â†“                      â†“                      â†“
   docs/*.md              docs/*.md              docs/*.md           docs/stories/*.md
```

### Key Capabilities

- **Interactive Interview**: 5 focused questions per agent
- **Conversation Memory**: Maintains context across sessions
- **Rich Document Output**: Markdown with tables, Mermaid diagrams, code examples
- **Automatic File Saving**: Documents saved to `/docs` folder
- **Workflow Chaining**: Story Builder can read PRD/TDR files directly
- **Jira Export**: Export user stories in Jira-compatible CSV
- **Tech Stack Analysis**: Get recommendations based on your stack
- **Multiple Export Formats**: Markdown, HTML, Confluence, Notion
- **Frontend Best Practices**: React/Next.js patterns from [Vercel's agent-skills](https://github.com/vercel-labs/agent-skills)

---

## ğŸš€ Quick Start

### Prerequisites

- **Node.js 22+** (required)
- **One of the following LLM providers:**
  - Ollama (local, free)
  - Ollama Cloud Models (free with Ollama account)
  - Groq (free tier available)
  - OpenAI (paid)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/document-architect.git
cd document-architect

# Install dependencies
npm install

# Copy environment template
cp env.example .env

# Configure your LLM provider (see below)
# Then run!
npm run architect
```

---

## ğŸ”§ LLM Provider Configuration

### Option 1: Ollama Cloud Models (Recommended - Free)

Ollama Cloud lets you run massive models (up to 671B parameters) via Ollama's infrastructure while using your local Ollama as a proxy. **No API key required!**

```bash
# 1. Install Ollama (v0.12+)
# macOS
brew install ollama

# Or download from https://ollama.com

# 2. Sign in to Ollama Cloud
ollama signin

# 3. Pull a cloud model
ollama pull qwen3-coder:480b-cloud
```

**Available Cloud Models:**
| Model | Size | Best For |
|-------|------|----------|
| `qwen3-coder:480b-cloud` | 480B | Code generation, TDRs |
| `gpt-oss:120b-cloud` | 120B | General purpose |
| `gpt-oss:20b-cloud` | 20B | Faster responses |
| `deepseek-v3.1:671b-cloud` | 671B | Most capable |

**Configure `.env`:**
```env
USE_OLLAMA=true
OLLAMA_MODEL=qwen3-coder:480b-cloud
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_API_KEY=ollama
```

---

### Option 2: Local Ollama (Free)

Run models entirely on your machine. Requires a GPU with sufficient VRAM.

```bash
# Install Ollama
brew install ollama

# Pull a local model
ollama pull llama3.2:3b      # Light (2GB VRAM)
ollama pull llama3:8b        # Medium (8GB VRAM)
ollama pull llama3:70b       # Heavy (40GB VRAM)
ollama pull codellama:7b     # For code-focused tasks
```

**Configure `.env`:**
```env
USE_OLLAMA=true
OLLAMA_MODEL=llama3:8b
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_API_KEY=ollama
```

---

### Option 3: Groq (Free Tier - Fast!)

Groq provides blazing-fast inference with a generous free tier.

1. Sign up at [console.groq.com](https://console.groq.com)
2. Create an API key

**Configure `.env`:**
```env
USE_OLLAMA=false
GROQ_API_KEY=gsk_your_api_key_here
```

**Available Models (via Groq):**
- `llama-3.3-70b-versatile` (default)
- `llama-3.1-8b-instant`
- `mixtral-8x7b-32768`

---

### Option 4: OpenAI (Paid)

For the highest quality outputs using GPT-4.

1. Get an API key from [platform.openai.com](https://platform.openai.com)
2. Modify `src/mastra/agents/architect.ts` to use OpenAI

**Configure `.env`:**
```env
OPENAI_API_KEY=sk-your_api_key_here
```

**Update the agent** (`src/mastra/agents/architect.ts`):
```typescript
function getModelConfig() {
  if (process.env.OPENAI_API_KEY) {
    return 'openai/gpt-4o';
  }
  // ... rest of config
}
```

---

### Option 5: Google Gemini (Free Tier)

1. Get an API key from [aistudio.google.com](https://aistudio.google.com)
2. Install the Gemini provider: `npm install @ai-sdk/google`

**Configure `.env`:**
```env
GOOGLE_API_KEY=your_api_key_here
```

**Update the agent:**
```typescript
import { google } from '@ai-sdk/google';

function getModelConfig() {
  if (process.env.GOOGLE_API_KEY) {
    return google('gemini-1.5-pro');
  }
  // ... rest of config
}
```

---

### Option 6: Anthropic Claude (Paid)

1. Get an API key from [console.anthropic.com](https://console.anthropic.com)
2. Install the Anthropic provider: `npm install @ai-sdk/anthropic`

**Configure `.env`:**
```env
ANTHROPIC_API_KEY=sk-ant-your_api_key_here
```

**Update the agent:**
```typescript
import { anthropic } from '@ai-sdk/anthropic';

function getModelConfig() {
  if (process.env.ANTHROPIC_API_KEY) {
    return anthropic('claude-3-5-sonnet-20241022');
  }
  // ... rest of config
}
```

---

## ğŸ“– Usage

### Quick Reference

| What You Want | Command | Access |
|---------------|---------|--------|
| Generate PRD/TDR via terminal | `npm run architect` | CLI |
| Generate PRD/TDR via web UI | `npm run dev` | http://localhost:4111 â†’ Architect Agent |
| Generate Frontend TDR | `npm run dev` | http://localhost:4111 â†’ Frontend Architect Agent |
| Generate User Stories | `npm run dev` | http://localhost:4111 â†’ Story Builder Agent |
| Auto-restart on changes | `npm run architect:dev` | CLI |

### Option 1: CLI Mode

The simplest way to use Document Architect:

```bash
# Start the interactive session
npm run architect

# With file watching (auto-restart on code changes)
npm run architect:dev
```

### Option 2: Mastra Playground (Web UI)

Mastra includes a built-in **Playground UI** for interacting with agents visually.

```bash
# Start the Mastra dev server
npm run dev
```

This starts the server at **http://localhost:4111**

#### Accessing the Playground

1. Open your browser to `http://localhost:4111`
2. Navigate to **Agents** in the sidebar
3. Select **"Architect Agent"**
4. Start chatting in the interactive UI!

#### Playground Features

- **Agent Chat** - Interactive UI for both agents
- **Tool Calls** - See when tools execute (saveDocument, etc.)
- **Logs** - Real-time debugging
- **API Explorer** - Test REST endpoints

#### REST API

```bash
# Chat with agent
POST http://localhost:4111/api/agents/architectAgent/generate
{ "messages": [{ "role": "user", "content": "I want to create a TDR" }] }

# Stream responses
POST http://localhost:4111/api/agents/architectAgent/stream
```

---

### CLI Example Session

```
$ npm run architect

ğŸ¤– Document Architect Agent
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ‘‹ Welcome to Document Architect!

I can help you create two types of documents:

ğŸ“‹ PRD Mode (Product Manager)
ğŸ—ï¸ TDR Mode (Principal Engineer)

Which mode would you like to use? (Type 'PRD' or 'TDR')

You: TDR

Great choice! Let's begin the Technical Design Review.
What system or feature are you designing?

You: A real-time collaborative document editor like Google Docs

Q1 - Architecture Overview:
"Walk me through the system architecture. What are the main components..."

[... 5 questions later ...]

âœ… TDR Generated Successfully!
ğŸ“„ Saved to: docs/collaborative-document-editor-tdr-2026-01-12.md
```

---

## ğŸ§ª Testing All Features

For a complete end-to-end test with sample responses for all agents, see:

ğŸ“– **[Complete Test Scenario](./docs/TEST-SCENARIO.md)**

The test scenario covers:
- PRD generation (Product Manager mode)
- TDR generation (Principal Engineer mode)  
- User story generation (Story Builder)
- Jira CSV export
- Tech stack analysis
- HTML & Confluence export

**Quick test:**
```bash
# Start the agent
npm run architect

# When prompted, type: PRD
# Follow the 5-question interview
# Document saves to: docs/[project-name]-prd-YYYY-MM-DD.md
```

---

## âš›ï¸ Frontend Architect Agent

Specialized in React/Next.js architecture with **45 rules from [Vercel's agent-skills](https://github.com/vercel-labs/agent-skills/tree/main/skills/react-best-practices)**, prioritized by impact.

```bash
npm run dev  # Open http://localhost:4111 â†’ Frontend Architect Agent
```

### Vercel Best Practices (8 Categories by Priority)

| Priority | Category | Impact | Key Rules |
|----------|----------|--------|-----------|
| 1 | **Eliminating Waterfalls** | CRITICAL | `async-parallel`, `async-suspense-boundaries` |
| 2 | **Bundle Size** | CRITICAL | `bundle-barrel-imports`, `bundle-dynamic-imports` |
| 3 | **Server Performance** | HIGH | `server-serialization`, `server-cache-react` |
| 4 | **Client Fetching** | MEDIUM-HIGH | `client-swr-dedup`, `client-passive-event-listeners` |
| 5 | **Re-render Optimization** | MEDIUM | `rerender-functional-setstate`, `rerender-derived-state` |
| 6 | **Rendering** | MEDIUM | `rendering-content-visibility`, `rendering-hydration-no-flicker` |
| 7 | **JS Performance** | LOW-MEDIUM | `js-tosorted-immutable`, `js-index-maps` |
| 8 | **Advanced Patterns** | LOW | `advanced-use-latest`, `advanced-event-handler-refs` |

### Interview Questions (Detects Anti-Patterns)

1. **Data Flow** - Detect sequential awaits, suggest `Promise.all()`
2. **Bundle Size** - Detect barrel imports, suggest direct imports
3. **Server/Client** - Detect over-serialization, suggest minimal props
4. **State & Re-renders** - Detect stale closures, suggest functional setState
5. **Performance** - Detect missing `content-visibility`, hydration flicker

### Frontend TDR Output

- Technology stack table with rationale
- Project structure (App Router, feature-based folders)
- Component hierarchy diagram (Mermaid)
- Server vs Client component patterns with code
- State management architecture
- Performance optimization techniques
- Accessibility implementation
- Testing strategy with examples
- Common pitfalls & solutions

---

## ğŸ› ï¸ Story Builder Agent

Transforms PRDs/TDRs into implementation-ready user stories with acceptance criteria, test cases, and sprint plans.

```bash
npm run dev  # Open http://localhost:4111 â†’ Story Builder Agent
```

### What It Generates

| Output | Description |
|--------|-------------|
| **Epics** | Grouped features with business value |
| **User Stories** | As a/I want/So that format |
| **Acceptance Criteria** | Given/When/Then testable criteria |
| **Test Cases** | Happy path, edge cases, error scenarios |
| **Sprint Plan** | Stories allocated by velocity |
| **Jira Export** | CSV ready for bulk import |

### Workflow Steps

```
Parse Doc â†’ Generate Epics â†’ Create Stories â†’ Add Details â†’ Sprint Plan â†’ Output
```

### Available Tools

| Tool | Description |
|------|-------------|
| `listDocumentsTool` | List PRDs/TDRs in /docs |
| `readDocumentTool` | Read document content |
| `saveStoriesTool` | Save to /docs/stories/ |
| `exportToJiraTool` | Export as Jira CSV |

---

## ğŸ—ï¸ How It Works

### Built with Mastra.ai

[Mastra](https://mastra.ai) is a TypeScript framework for building AI agents. This project demonstrates:

1. **Agent Definition** (`src/mastra/agents/architect.ts`)
   - System instructions for PM and Engineer personas
   - Dynamic model configuration (Ollama/Groq/OpenAI)
   - Attached tools for document generation

2. **Tools** (`src/mastra/tools/file-tools.ts`)
   - `saveDocumentTool`: Saves generated markdown to disk
   - `generateDiagramTool`: Creates Mermaid.js diagrams

3. **Memory** (SQLite via LibSQL)
   - Persists conversation history across sessions
   - Enables context-aware follow-up questions

4. **CLI Runner** (`run.ts`)
   - Interactive readline interface
   - Handles user input/output loop

### Project Structure

```
architect-agent/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ mastra/
â”‚       â”œâ”€â”€ agents/
â”‚       â”‚   â”œâ”€â”€ architect.ts           # Document Architect (PRD/TDR)
â”‚       â”‚   â”œâ”€â”€ frontend-architect.ts  # Frontend Architect (React/Next.js)
â”‚       â”‚   â””â”€â”€ story-builder.ts       # Story Builder (User Stories)
â”‚       â”œâ”€â”€ tools/
â”‚       â”‚   â”œâ”€â”€ file-tools.ts          # PRD/TDR tools + export formats
â”‚       â”‚   â””â”€â”€ story-tools.ts         # Story tools + Jira export
â”‚       â”œâ”€â”€ workflows/
â”‚       â”‚   â””â”€â”€ story-builder-workflow.ts
â”‚       â””â”€â”€ index.ts                   # Mastra instance export
â”œâ”€â”€ docs/                              # Generated documents
â”‚   â”œâ”€â”€ stories/                       # User stories
â”‚   â””â”€â”€ exports/                       # HTML, Confluence, Jira
â”œâ”€â”€ run.ts                             # CLI entry point
â”œâ”€â”€ env.example
â””â”€â”€ README.md
```

---

## ğŸ¯ Who Is This For?

| Role | Use Case |
|------|----------|
| **Product Managers** | PRD templates, structured interviews, consistent output |
| **Engineers** | TDRs with security, scalability, code examples, pitfalls |
| **Scrum Masters** | User stories, acceptance criteria, sprint planning |
| **QA Engineers** | Test cases, DoD checklists, edge case coverage |

## ğŸ“ Output Sections

| PRD | TDR | Stories |
|-----|-----|---------|
| Executive Summary | Architecture Diagram (Mermaid) | Epics Overview |
| Problem Statement | Security Design + Code | User Stories |
| Target Persona | Database Schema (SQL) | Acceptance Criteria |
| Success Metrics | Scalability Patterns | Test Cases |
| Requirements (P0/P1/P2) | Rate Limiting Code | Sprint Plan |
| Timeline & Risks | Common Pitfalls | Jira CSV |

---

## ğŸ› ï¸ Development

| Command | Description |
|---------|-------------|
| `npm run architect` | CLI mode |
| `npm run dev` | Web UI at http://localhost:4111 |
| `npm run build` | Build for production |

**Adding new LLM providers:** Install the AI SDK package, update `getModelConfig()` in `architect.ts`, add env variable.

---

## ğŸ” Security

- Never commit `.env` files (already in `.gitignore`)
- Rotate leaked keys immediately
- The `env.example` is safe to commit

---

## ğŸ“š Resources

- [Mastra Docs](https://docs.mastra.ai) â€¢ [Mastra GitHub](https://github.com/mastra-ai/mastra)
- [Ollama Cloud Models](https://ollama.com/blog/cloud-models)
- [Complete Test Scenario](./docs/TEST-SCENARIO.md)

---

## ğŸ“„ License

MIT License

---

**Built with [Mastra.ai](https://mastra.ai)** â€¢ Powered by Ollama, Groq, OpenAI, Anthropic, Google
